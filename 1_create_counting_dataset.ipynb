{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c1bae-7c14-4196-a23b-8e6b97a58850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (it has multiple splits)\n",
    "dataset = load_dataset(\"nielsr/countbench\")\n",
    "\n",
    "# Let's assume you're using the 'train' split\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "# Convert the first 10 examples to a Pandas DataFrame\n",
    "df = pd.DataFrame(train_data)\n",
    "\n",
    "# Show the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b58493-be3b-49e5-8bb9-0b89d14b10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"INSERT API KEY\"\n",
    "\n",
    "client = openai.OpenAI(api_key=API_KEY)\n",
    "\n",
    "# Convert PIL image to base64 image URL dict\n",
    "def pil_to_base64_image_url(image: \"PIL.Image.Image\"):\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    b64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return {\n",
    "        \"url\": f\"data:image/png;base64,{b64}\",\n",
    "        \"detail\": \"high\"\n",
    "    }\n",
    "\n",
    "# Query GPT-4o with image+caption\n",
    "def get_named_object_from_image(image, caption=None, model=\"gpt-4o\"):\n",
    "    if image is None:\n",
    "        return \"IMAGE_MISSING\"\n",
    "\n",
    "    try:\n",
    "        image_dict = pil_to_base64_image_url(image)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful visual assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": (\n",
    "                            \"You will be shown an image. Identify the main object(s) in the image. \"\n",
    "                            \"Respond with just the object name(s) in lowercase, one or two words max. \"\n",
    "                            \"If there are multiple objects (like two kids), just say 'kids'. Don't list more than one object, only the object that is repeating. \"\n",
    "                            \"Avoid sentences and do not include counts.\"\n",
    "                        ),\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": image_dict\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        if caption:\n",
    "            messages[1][\"content\"].insert(0, {\"type\": \"text\", \"text\": f\"The caption says: {caption}\"})\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            max_tokens=50,\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content.strip()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"ERROR\"\n",
    "\n",
    "# Apply to DataFrame\n",
    "def name_objects_in_dataframe(df, model=\"gpt-4o\"):\n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        print(f\"\\n Processing row {idx}\")\n",
    "        result = get_named_object_from_image(row[\"image\"], caption=row.get(\"text\", None), model=model)\n",
    "        results.append(result)\n",
    "\n",
    "    df[\"gpt_named_object\"] = results\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6f779-cd3f-4be4-a616-d4d0ca6e4697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = name_objects_in_dataframe(df, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e26ce-4edf-4ef0-b255-a4987a5bf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"gpt_named_object\"] != \"IMAGE_MISSING\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adab84b-8a79-47c7-ad62-f81e6e09cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"gpt_named_object\"].str.contains(\"sorry\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291e969b-66d7-4cbc-8062-77f61cd87cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"gpt_responses_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938bfec-4ae4-4252-9660-86eb3d556706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prompt_count\"] = df[\"gpt_named_object\"].apply(\n",
    "    lambda obj: f\"How many {obj} are in this image?\"\n",
    ")\n",
    "\n",
    "# Prompts 2â€“6: Describe the (number + x) <objects>\n",
    "for i in range(1, 6):\n",
    "    df[f\"prompt_describe_plus_{i}\"] = df.apply(\n",
    "        lambda row: f\"Describe the {row['number'] + i} {row['gpt_named_object']} in this image.\"\n",
    "        if isinstance(row['number'], int)\n",
    "        else f\"Describe the {row['gpt_named_object']} in this image.\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# Show relevant columns\n",
    "columns_to_show = [\"gpt_named_object\", \"number\", \"prompt_count\"] + [f\"prompt_describe_plus_{i}\" for i in range(1, 6)]\n",
    "print(df[columns_to_show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01787ab6-13cd-49ce-9b73-d02f33dcb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hf = train_data\n",
    "\n",
    "# Merge on shared key: we assume 'image_url' is the key both have\n",
    "merged_df = df.drop(columns=[\"image\"], errors=\"ignore\").merge(\n",
    "    df_hf[[\"image_url\", \"image\"]], on=\"image_url\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753db93-532a-4b48-a738-c8386d0d9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save images and create 'path' column\n",
    "os.makedirs(\"countbench_images\", exist_ok=True)\n",
    "\n",
    "def save_image(row, folder=\"countbench_images\"):\n",
    "    try:\n",
    "        img = row[\"image\"]\n",
    "        filename = f\"{row.name:04d}.png\"\n",
    "        path = os.path.join(folder, filename)\n",
    "        img.save(path)\n",
    "        return path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save image at index {row.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "merged_df[\"path\"] = merged_df.apply(save_image, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925d41c-ccbf-4674-8b2d-6c697501e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_folder = \"countbench_images\"\n",
    "num_images = len([\n",
    "    f for f in os.listdir(image_folder)\n",
    "    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "])\n",
    "\n",
    "print(f\"Number of images in '{image_folder}': {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d3fe4-d037-433a-90e7-8c8b1762a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [10, 20, 50]:\n",
    "    merged_df[f\"prompt_describe_plus_{i}\"] = merged_df.apply(\n",
    "        lambda row: f\"Describe the {row['number'] + i} {row['gpt_named_object']} in this image.\"\n",
    "        if isinstance(row['number'], int)\n",
    "        else f\"Describe the {row['gpt_named_object']} in this image.\",\n",
    "        axis=1\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b455a-1c66-4a1b-9110-40b7eed0e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"counting_with_prompts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1779cc8-c29f-4779-b4c2-b5394f6d3c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prompt_describe_plus_1',\n",
       " 'prompt_describe_plus_2',\n",
       " 'prompt_describe_plus_3',\n",
       " 'prompt_describe_plus_4',\n",
       " 'prompt_describe_plus_5',\n",
       " 'prompt_describe_plus_10',\n",
       " 'prompt_describe_plus_20',\n",
       " 'prompt_describe_plus_50']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"prompt_describe_plus_{i}\" for i in [1, 2, 3, 4, 5, 10, 20, 50]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
